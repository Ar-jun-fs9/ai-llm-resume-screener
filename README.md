<div align="center">

# ğŸ¤– AI-Powered Resume Screener with LLM

**Smart candidate ranking and AI-powered resume summarization using TinyLlama**

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-Web%20Framework-green.svg)](https://flask.palletsprojects.com)
[![Local LLM](https://img.shields.io/badge/%20LLM-TinyLlama-orange.svg)](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)

_Process resumes, rank candidates by job fit, and generate AI summaries - all locally on your machine_

</div>

---

## ğŸš€ Features

- **ğŸ“„ Resume Processing**: Upload PDF/DOCX resume files
- **ğŸ“ Job Description Analysis**: Upload job requirements in TXT format
- **ğŸ¯ AI-Powered Ranking**: Semantic similarity ranking using advanced embeddings
- **ğŸ¤– Local LLM Summarization**: AI-generated summaries with TinyLlama
- **ğŸ“Š CSV Export**: Download complete ranking results
- **ğŸ”’ Privacy-First**: All processing happens locally, no data sent externally

---

## âš ï¸ First Run Important Notes

**When you first run the application after cloning/downloading, you'll see these models being downloaded:**

```
Successfully loaded LLM model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
Successfully loaded Embedding model: all-MiniLM-L6-v2
```

### ğŸ“¦ Model Download Information

| Model                        | Size   | Purpose                      | Cache Location  |
| ---------------------------- | ------ | ---------------------------- | --------------- |
| **TinyLlama-1.1B-Chat-v1.0** | ~1-2GB | LLM for resume summarization | `.cache` folder |
| **all-MiniLM-L6-v2**         | ~100MB | Semantic embeddings          | `.cache` folder |

**Important:**

- **Download Frequency**: Models are downloaded **only once** and cached permanently
- **First Run Time**: 5-15 minutes depending on your internet connection
- **Subsequent Runs**: Models load instantly from cache
- **Disk Space**: ~2GB total for all models

### âš¡ Performance Expectations

- **Current Summary Generation**: ~1 minute per candidate (CPU-only inference)
- **Hardware Consideration**: Optimized for laptop specs - higher-end systems may experience lag
- **Future Updates**: Will optimize to achieve sub-1-second summary generation

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- Python 3.7+
- 8GB+ RAM (for TinyLlama model loading)
- ~2GB disk space for model downloads
- CPU-only (no GPU required)

### Quick Start

```bash
# 1. Clone or download the project
git clone https://github.com/Ar-jun-fs9/ai-llm-resume-screener.git
cd ai-llm-resume-screener

# 2. Install dependencies
pip install -r requirements.txt

# 3. First run (models will download automatically)
python app.py

# 4. Open your browser
# Navigate to http://localhost:5000
```

---

## ğŸ¯ How It Works

### 1. Similarity Scoring Algorithm

The application uses **cosine similarity** to rank candidates based on semantic matching between resumes and job descriptions:

#### **Step-by-Step Process:**

1. **Text Extraction**: Resume and job description text is extracted from uploaded files
2. **Text Preprocessing**: Text is cleaned and normalized for better matching
3. **Embedding Generation**: Both texts are converted to high-dimensional vectors using `all-MiniLM-L6-v2`
4. **Similarity Calculation**: Cosine similarity is computed between resume and job embeddings
5. **Score Normalization**: Results are sorted by similarity score (highest first) and similarity score (0-1) is converted to percentage for display

#### **Color Coding:**

- ğŸŸ¢ **Green (â‰¥70%)**: Excellent match - highly qualified
- ğŸŸ¡ **Yellow (40-69%)**: Good match - worth considering
- ğŸ”´ **Red (<40%)**: Poor match - may not be suitable

### 2. AI-Powered Summarization

Using **TinyLlama-1.1B-Chat-v1.0** for local LLM analysis:

1. **Context Preparation**: Resume and job description are prepared for LLM input
2. **Prompt Engineering**: Structured prompt guides the AI to analyze candidate fit
3. **Text Generation**: TinyLlama generates detailed assessment including:
   - Key candidate skills
   - Overall role compatibility
   - Strengths and potential gaps
   - Structured evaluation

---

## ğŸ“– Usage Guide

### Step 1: Upload Files

- **Resumes**: Select multiple PDF/DOCX files
- **Job Description**: Select one TXT file

### Step 2: Rank Candidates

- Click **"Rank Candidates"** to process all files
- View ranked results with similarity percentages

### Step 3: Generate Summaries

- Click **"Summarize"** button for any candidate
- AI generates detailed assessment using local TinyLlama model

### Step 4: Export Results

- Click **"Download Results (CSV)"** to export all rankings

---

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ app.py                     # Main Flask application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract_text.py        # PDF/DOCX text extraction
â”‚   â”œâ”€â”€ preprocess.py          # Text preprocessing & cleaning
â”‚   â”œâ”€â”€ embeddings.py          # Sentence transformer embeddings
â”‚   â”œâ”€â”€ similarity.py          # Cosine similarity calculation
â”‚   â”œâ”€â”€ rank_candidates.py     # Candidate ranking & CSV export
â”‚   â””â”€â”€ local_llm.py           # TinyLlama integration
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Main web interface
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css          # Custom styles
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ index.js           # Frontend interactions
â”œâ”€â”€ output/                    # Generated CSV files
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## ğŸš€ Future Enhancements

- **âš¡ Performance Optimization**: Target sub-1-second summary generation
- **ğŸ¯ Enhanced Models**: Integration of faster, more capable LLMs
- **ğŸ“± Mobile Interface**: Responsive design improvements
- **ğŸ”„ Batch Processing**: Multiple job descriptions simultaneously
- **ğŸ“Š Analytics Dashboard**: Detailed recruitment insights
- **â˜ï¸ Cloud Integration**: Optional cloud model support

---
## ğŸ™ Acknowledgments

- **TinyLlama Team**: For the lightweight chat model
- **Sentence Transformers**: For semantic embedding capabilities
- **Flask Community**: For the excellent web framework
- **Hugging Face**: For model hosting and transformers library

---

**Built with**

[![Made with Python](https://img.shields.io/badge/Made%20with-Python-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-black.svg?labelColor=orange)](#)


