<div align="center">

# ü§ñ AI-Powered Resume Screener with LLM

**Smart candidate ranking and AI-powered resume summarization using TinyLlama**

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-Web%20Framework-green.svg)](https://flask.palletsprojects.com)
[![Local LLM](https://img.shields.io/badge/%20LLM-TinyLlama-orange.svg)](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)
[![Embedding Model](https://img.shields.io/badge/Embedding--Model-all--MiniLM--L6--v2-lightgrey.svg)](https://www.sbert.net/docs/pretrained_models.html#sentence-transformersall-minilm-l6-v2)

_Process resumes, rank candidates by job fit, and generate AI summaries - all locally on your machine_

</div>

---

## üöÄ Features

- **üìÑ Resume Processing**: Upload PDF/DOCX resume files
- **üìù Job Description Analysis**: Upload job requirements in TXT format
- **üéØ AI-Powered Ranking**: Semantic similarity ranking using advanced embeddings
- **ü§ñ Local LLM Summarization**: AI-generated summaries with TinyLlama
- **üìä CSV Export**: Download complete ranking results
- **üîí Privacy-First**: All processing happens locally, no data sent externally

---

## ‚ö†Ô∏è First Run Important Notes

**When you first run the application after cloning/downloading, you'll see these models being downloaded:**

```
Successfully loaded LLM model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
Successfully loaded Embedding model: all-MiniLM-L6-v2
```

### üì¶ Model Download Information

| Model                        | Size   | Purpose                      | Cache Location  |
| ---------------------------- | ------ | ---------------------------- | --------------- |
| **TinyLlama-1.1B-Chat-v1.0** | ~1-2GB | LLM for resume summarization | `.cache` folder |
| **all-MiniLM-L6-v2**         | ~100MB | Semantic embeddings          | `.cache` folder |

**Important:**

- **Download Frequency**: Models are downloaded **only once** and cached permanently
- **First Run Time**: 5-15 minutes depending on your internet connection
- **Subsequent Runs**: Models load instantly from cache
- **Disk Space**: ~2GB total for all models

### ‚ö° Performance Expectations

- **Current Summary Generation**: ~1 minute per candidate (CPU-only inference)
- **Hardware Consideration**: Optimized for laptop specs - higher-end systems may experience lag
- **Future Updates**: Will optimize to achieve sub-1-second summary generation

---

## üõ†Ô∏è Installation & Setup

### Prerequisites

- Python 3.7+
- 8GB+ RAM (for TinyLlama model loading)
- ~2GB disk space for model downloads
- CPU-only (no GPU required)

### Quick Start

```bash
# 1. Clone or download the project
git clone https://github.com/Ar-jun-fs9/ai-llm-resume-screener.git
cd ai-llm-resume-screener

# 2. Install dependencies
pip install -r requirements.txt

# 3. First run (models will download automatically)
python app.py

# 4. Open your browser
# Navigate to http://localhost:5000
```

---

## üéØ How It Works

### 1. Similarity Scoring Algorithm

The application uses **cosine similarity** to rank candidates based on semantic matching between resumes and job descriptions:

#### **Step-by-Step Process:**

1. **Text Extraction**: Resume and job description text is extracted from uploaded files
2. **Text Preprocessing**: Text is cleaned and normalized for better matching
3. **Embedding Generation**: Both texts are converted to high-dimensional vectors using `all-MiniLM-L6-v2`
4. **Similarity Calculation**: Cosine similarity is computed between resume and job embeddings
5. **Score Normalization**: Results are sorted by similarity score (highest first) and similarity score (0-1) is converted to percentage for display

#### **Color Coding:**

- üü¢ **Green (‚â•70%)**: Excellent match - highly qualified
- üü° **Yellow (40-69%)**: Good match - worth considering
- üî¥ **Red (<40%)**: Poor match - may not be suitable

### 2. AI-Powered Summarization

Using **TinyLlama-1.1B-Chat-v1.0** for local LLM analysis:

1. **Context Preparation**: Resume and job description are prepared for LLM input
2. **Prompt Engineering**: Structured prompt guides the AI to analyze candidate fit
3. **Text Generation**: TinyLlama generates detailed assessment including:
   - Key candidate skills
   - Overall role compatibility
   - Strengths and potential gaps
   - Structured evaluation

---

## üìñ Usage Guide

### Step 1: Upload Files

- **Resumes**: Select multiple PDF/DOCX files
- **Job Description**: Select one TXT file

### Step 2: Rank Candidates

- Click **"Rank Candidates"** to process all files
- View ranked results with similarity percentages

### Step 3: Generate Summaries

- Click **"Summarize"** button for any candidate
- AI generates detailed assessment using local TinyLlama model

### Step 4: Export Results

- Click **"Download Results (CSV)"** to export all rankings

---

## üèóÔ∏è Project Structure

```
tiny-llama-rag/
‚îú‚îÄ‚îÄ üìÑ app.py                          # Main Flask application
‚îú‚îÄ‚îÄ üìÅ src/                            # Core Python modules
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ extract_text.py             # PDF/DOCX text extraction
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ preprocess.py               # Text preprocessing & cleaning
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ embeddings.py               # Sentence transformer embeddings
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ similarity.py               # Cosine similarity calculation
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ rank_candidates.py          # Candidate ranking & CSV export
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ local_llm.py                # TinyLlama integration
‚îú‚îÄ‚îÄ üìÅ templates/
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ index.html                  # Main web interface
‚îú‚îÄ‚îÄ üìÅ static/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ css/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ style.css               # Custom styles
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ js/
‚îÇ       ‚îî‚îÄ‚îÄ üìÑ index.js                # Frontend interactions
‚îú‚îÄ‚îÄ üìÅ output/                         # Generated CSV files
‚îî‚îÄ‚îÄ üìÑ requirements.txt                # Python dependencies
```

---

## üöÄ Future Enhancements

- **‚ö° Performance Optimization**: Target sub-1-second summary generation
- **üéØ Enhanced Models**: Integration of faster, more capable LLMs
- **üì± Mobile Interface**: Responsive design improvements
- **üîÑ Batch Processing**: Multiple job descriptions simultaneously
- **üìä Analytics Dashboard**: Detailed recruitment insights
- **‚òÅÔ∏è Cloud Integration**: Optional cloud model support

---
## üôè Acknowledgments

- **TinyLlama Team**: For the lightweight chat model
- **Sentence Transformers**: For semantic embedding capabilities
- **Flask Community**: For the excellent web framework
- **Hugging Face**: For model hosting and transformers library

---

**License**

[![License](https://img.shields.io/badge/license-MIT-black.svg?labelColor=orange)](#)

<div align="center">
   
  **[‚¨Ü Back to Top](#ai-powered-resume-screener-with-llm)**
  
</div>





